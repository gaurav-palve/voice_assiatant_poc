# POC Setup with Python LLM Service

## âœ… What Was Created

```
poc/
â”œâ”€â”€ python_service/          â† NEW: Python LLM Service
â”‚   â”œâ”€â”€ main.py              # FastAPI server with OpenAI
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â”œâ”€â”€ .env                  # OpenAI API key
â”‚   â””â”€â”€ README.md             # Python service docs
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ customPythonAgent.ts  â† NEW: Custom agent for Python
â”‚   â”‚   â”œâ”€â”€ agents.ts             â† UPDATED: Added pythonCustom()
â”‚   â”‚   â”œâ”€â”€ call.ts               â† UPDATED: Uses Python agent
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ client/
    â””â”€â”€ ...
```

## ğŸš€ Complete Setup Steps

### **Step 1: Start Python LLM Service**

Open **PowerShell Terminal 1:**

```powershell
cd c:\Users\gaurav.palve\Desktop\testing_gaurav\micdrop\poc\python_service

# Install dependencies (first time only)
pip install -r requirements.txt

# Run Python service
python main.py
```

**Expected output:**
```
INFO:     Uvicorn running on http://127.0.0.1:5000
```

### **Step 2: Start Micdrop POC**

Open **PowerShell Terminal 2:**

```powershell
cd c:\Users\gaurav.palve\Desktop\testing_gaurav\micdrop\poc

# Run Micdrop (server + client)
pnpm dev
```

**Expected output:**
```
[server] POC Server running on port 8081
[client] âœ  Local:   http://localhost:5173/
```

### **Step 3: Open Browser**

Open: **http://localhost:5173/**

## ğŸ¤ How It Works Now

```
User Voice (Microphone)
    â†“
Gladia (Speech-to-Text)
    â†“
Python LLM Service (OpenAI + Your Documents)
    â†“
ElevenLabs (Text-to-Speech)
    â†“
User Speaker (Audio Response)
```

## ğŸ“š Customizing Your Documents

Edit `poc/python_service/main.py` and update the `DOCUMENTS` variable with your knowledge base:

```python
DOCUMENTS = """
You are a helpful AI assistant with access to the following documents:

=== KNOWLEDGE BASE ===

Your Company Info:
- Product: Your product name
- Founded: Year
- Website: https://example.com

Customer Support FAQ:
- Q: How do I get started?
- A: Visit our website...

Technical Documentation:
- Feature 1: Description
- Feature 2: Description

=== END KNOWLEDGE BASE ===
"""
```

The LLM will now answer questions based on your documents!

## ğŸ”‘ API Keys Setup

All API keys are already configured:

- âœ… **OpenAI** in `poc/python_service/.env` and `poc/server/.env`
- âœ… **Gladia** in `poc/server/.env`
- âœ… **ElevenLabs** in `poc/server/.env`

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Browser Client                           â”‚
â”‚                  (http://localhost:5173)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ WebSocket
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Node.js Server (port 8081)                     â”‚
â”‚  - Handles WebSocket connections                           â”‚
â”‚  - Manages audio streams                                   â”‚
â”‚  - Calls Python LLM service                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ HTTP POST
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Python LLM Service (port 5000)                    â”‚
â”‚  - FastAPI server                                          â”‚
â”‚  - OpenAI integration with documents                       â”‚
â”‚  - Custom knowledge base                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

- âœ… Voice-to-voice conversation
- âœ… Custom Python LLM with documents
- âœ… Uses OpenAI API (not locked to one provider)
- âœ… Document context for answers
- âœ… Gladia for accurate speech recognition
- âœ… ElevenLabs for natural voice responses
- âœ… Real-time transcript display
- âœ… Easy to customize

## ğŸ”§ Troubleshooting

| Issue | Solution |
|-------|----------|
| Python service won't start | Run `pip install -r requirements.txt` |
| "Connection refused" error | Make sure Python service is running |
| No response from AI | Check OpenAI API key in .env files |
| Blank transcript | Check browser console for errors |
| Port already in use | Kill process or change port number |

## ğŸš€ Quick Commands

```powershell
# Python service
cd poc\python_service
python main.py

# Micdrop POC
cd poc
pnpm dev

# Install Python deps
pip install -r requirements.txt

# Check Python service health
curl http://127.0.0.1:5000/health
```

## ğŸ“– Next Steps

1. **Customize documents** in `poc/python_service/main.py`
2. **Add more context** to improve AI responses
3. **Test voice conversation** and refine prompts
4. **Deploy** Python service to production server

---

**Everything is set up and ready to go!** ğŸ‰

Run both services and start talking to your custom AI! ğŸ¤
